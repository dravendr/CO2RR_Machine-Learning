{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost \n",
    "import lightgbm\n",
    "import catboost\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib \n",
    "import shap\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def compute_mae_mse_rmse(target,prediction):\n",
    "    error = []\n",
    "    for i in range(len(target)):\n",
    "        error.append(target[i] - prediction[i])\n",
    "    squaredError = []\n",
    "    absError = []\n",
    "    for val in error:\n",
    "        squaredError.append(val * val)  # target-prediction之差平方\n",
    "        absError.append(abs(val))  # 误差绝对值\n",
    "    mae=sum(absError)/len(absError)  # 平均绝对误差MAE\n",
    "    mse=sum(squaredError)/len(squaredError)  # 均方误差MSE\n",
    "    RMSE=np.sqrt(sum(squaredError)/len(squaredError))\n",
    "    R2=r2_score(target,prediction)\n",
    "    return mae,mse,RMSE,R2\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database_filled_MFECD.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[\n",
    "                     'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH',#18\n",
    "                      'Partial Current Density at Maximum FE (mA/cm2)'#19\n",
    "                        ]]\n",
    "\n",
    "\n",
    "\n",
    "###########defining a wrapper function for later call from each machine learning algorithms##########\n",
    "raw_input=raw_data.iloc[:,0:19]\n",
    "raw_output=raw_data.iloc[:,19]\n",
    "# raw_input_global=raw_data.iloc[:,0:32]\n",
    "# raw_output_global=raw_data.iloc[:,32]\n",
    "X=raw_input.values.astype(np.float32)\n",
    "y=raw_output.values.astype(np.float32)\n",
    "###########wrap up fuction for later call for OPTIMIZATION##########\n",
    "def evaluate(pre_2,real_2):\n",
    "    pre_2=np.array(pre_2)\n",
    "    real_2=np.array(real_2)\n",
    "    pre_2_series=pd.Series(pre_2)\n",
    "    real_2_series=pd.Series(real_2)\n",
    "    return rmse(pre_2,real_2), round(pre_2_series.corr(real_2_series), 3)\n",
    "def compare(list_name,limit):\n",
    "    judge=1\n",
    "    for a in list_name:\n",
    "        if a < limit:\n",
    "            judge=judge*1\n",
    "        else:\n",
    "            judge=judge*0\n",
    "    return judge\n",
    "def generate_arrays_from_file(path):\n",
    "    while True:\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                # create numpy arrays of input data\n",
    "                # and labels, from each line in the file\n",
    "                x1, x2, y = process_line(line)\n",
    "                yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model,param,algorithm_name):\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5,n_jobs=-1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    result = best_model.predict(X_test)\n",
    "    x_prediction_07=result\n",
    "    y_real_07=y_test.values\n",
    "    x_prediction_07_series=pd.Series(x_prediction_07)\n",
    "    y_real_07_series=pd.Series(y_real_07)\n",
    "    \n",
    "    result_train = best_model.predict(X_train)\n",
    "    x_prediction_07_train=result_train\n",
    "    y_real_07_train=y_train.values\n",
    "    x_prediction_07_series_train=pd.Series(x_prediction_07_train)\n",
    "    y_real_07_series_train=pd.Series(y_real_07_train)\n",
    "    \n",
    "    ###########evaluating the regression quality##########\n",
    "    corr_ann = round(x_prediction_07_series.corr(y_real_07_series), 5)\n",
    "    error_val= compute_mae_mse_rmse(x_prediction_07,y_real_07)\n",
    "    \n",
    "    corr_ann_train = round(x_prediction_07_series_train.corr(y_real_07_series_train), 5)\n",
    "    error_val_train= compute_mae_mse_rmse(x_prediction_07_train,y_real_07_train)\n",
    "    \n",
    "    print(algorithm_name)\n",
    "    print(best_model.feature_importances_)\n",
    "    print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    print(error_val,'TEST R2',error_val[3],'TEST CORR',corr_ann)\n",
    "    print(error_val_train,'TRAIN R2',error_val_train[3],'TRAIN CORR',corr_ann_train)\n",
    "    x_y_x=np.arange(0.2,1.1,0.1)\n",
    "    x_y_y=np.arange(0.2,1.1,0.1)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x_prediction_07,y_real_07,color='red',label=algorithm_name+' Test Set',alpha=0.75)\n",
    "    ax.scatter(x_prediction_07_train,y_real_07_train,color='blue',label=algorithm_name+' Training Set',alpha=0.25,marker=\"^\")\n",
    "    ax.plot(x_y_x,x_y_y)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u\"Predicted_Overpotential_@_Maximum_Faradic_Efficiency\")\n",
    "    plt.ylabel(u\"Real_Overpotential_@_Maximum_Faradic_Efficiency\")\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=36\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_input, raw_output, test_size=.1,random_state=seed)\n",
    "raw_param=raw_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pdpbox.pdp_calc_utils import _calc_ice_lines_inter\n",
    "from pdpbox.pdp import pdp_isolate, PDPInteract\n",
    "from pdpbox.utils import (_check_model, _check_dataset, _check_percentile_range, _check_feature,\n",
    "                    _check_grid_type, _check_memory_limit, _make_list,\n",
    "                    _calc_memory_usage, _get_grids, _get_grid_combos, _check_classes)\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def pdp_multi_interact(model, dataset, model_features, features, \n",
    "                    num_grid_points=None, grid_types=None, percentile_ranges=None, grid_ranges=None, cust_grid_points=None, \n",
    "                    cust_grid_combos=None, use_custom_grid_combos=False,\n",
    "                    memory_limit=0.9, n_jobs=8, predict_kwds=None, data_transformer=None):\n",
    "\n",
    "    def _expand_default(x, default, length):\n",
    "        if x is None:\n",
    "            return [default] * length\n",
    "        return x\n",
    "\n",
    "    def _get_grid_combos(feature_grids, feature_types):\n",
    "        grids = [np.array(list(feature_grid),dtype=np.float16) for feature_grid in feature_grids]\n",
    "        for i in range(len(feature_types)):\n",
    "            if feature_types[i] == 'onehot':\n",
    "                grids[i] = np.eye(len(grids[i])).astype(int).tolist()\n",
    "        return np.stack(np.meshgrid(*grids,copy=bool), -1).reshape(-1, len(grids))\n",
    "\n",
    "    if predict_kwds is None:\n",
    "        predict_kwds = dict()\n",
    "\n",
    "    nr_feats = len(features)\n",
    "\n",
    "    # check function inputs\n",
    "    n_classes, predict = _check_model(model=model)\n",
    "    _check_dataset(df=dataset)\n",
    "    _dataset = dataset.copy()\n",
    "\n",
    "    # prepare the grid\n",
    "    pdp_isolate_outs = []\n",
    "    if use_custom_grid_combos:\n",
    "        grid_combos = cust_grid_combos\n",
    "        feature_grids = []\n",
    "        feature_types = []\n",
    "    else:\n",
    "        num_grid_points = _expand_default(x=num_grid_points, default=10, length=nr_feats)\n",
    "        grid_types = _expand_default(x=grid_types, default='percentile', length=nr_feats)\n",
    "        for i in range(nr_feats):\n",
    "            _check_grid_type(grid_type=grid_types[i])\n",
    "\n",
    "        percentile_ranges = _expand_default(x=percentile_ranges, default=None, length=nr_feats)\n",
    "        for i in range(nr_feats):\n",
    "            _check_percentile_range(percentile_range=percentile_ranges[i])\n",
    "\n",
    "        grid_ranges = _expand_default(x=grid_ranges, default=None, length=nr_feats)\n",
    "        cust_grid_points = _expand_default(x=cust_grid_points, default=None, length=nr_feats)\n",
    "\n",
    "        _check_memory_limit(memory_limit=memory_limit)\n",
    "\n",
    "        pdp_isolate_outs = []\n",
    "        for idx in range(nr_feats):\n",
    "            pdp_isolate_out = pdp_isolate(\n",
    "                model=model, dataset=_dataset, model_features=model_features, feature=features[idx],\n",
    "                num_grid_points=num_grid_points[idx], grid_type=grid_types[idx], percentile_range=percentile_ranges[idx],\n",
    "                grid_range=grid_ranges[idx], cust_grid_points=cust_grid_points[idx], memory_limit=memory_limit,\n",
    "                n_jobs=n_jobs, predict_kwds=predict_kwds, data_transformer=data_transformer)\n",
    "            pdp_isolate_outs.append(pdp_isolate_out)\n",
    "\n",
    "        if n_classes > 2:\n",
    "            feature_grids = [pdp_isolate_outs[i][0].feature_grids for i in range(nr_feats)]\n",
    "            feature_types = [pdp_isolate_outs[i][0].feature_type  for i in range(nr_feats)]\n",
    "        else:\n",
    "            feature_grids = [pdp_isolate_outs[i].feature_grids for i in range(nr_feats)]\n",
    "            feature_types = [pdp_isolate_outs[i].feature_type  for i in range(nr_feats)]\n",
    "\n",
    "        grid_combos = _get_grid_combos(feature_grids, feature_types)\n",
    "\n",
    "    feature_list = []\n",
    "    for i in range(nr_feats):\n",
    "        feature_list.extend(_make_list(features[i]))\n",
    "\n",
    "    # Parallel calculate ICE lines\n",
    "    true_n_jobs = _calc_memory_usage(\n",
    "        df=_dataset, total_units=len(grid_combos), n_jobs=n_jobs, memory_limit=memory_limit)\n",
    "\n",
    "    grid_results = Parallel(n_jobs=true_n_jobs)(delayed(_calc_ice_lines_inter)(\n",
    "        grid_combo, data=_dataset, model=model, model_features=model_features, n_classes=n_classes,\n",
    "        feature_list=feature_list, predict_kwds=predict_kwds, data_transformer=data_transformer)\n",
    "                                                for grid_combo in grid_combos)\n",
    "\n",
    "    ice_lines = pd.concat(grid_results, axis=0).reset_index(drop=True)\n",
    "    pdp = ice_lines.groupby(feature_list, as_index=False).mean()\n",
    "\n",
    "    # combine the final results\n",
    "    pdp_interact_params = {'n_classes': n_classes, \n",
    "                        'features': features, \n",
    "                        'feature_types': feature_types,\n",
    "                        'feature_grids': feature_grids}\n",
    "    if n_classes > 2:\n",
    "        pdp_interact_out = []\n",
    "        for n_class in range(n_classes):\n",
    "            _pdp = pdp[feature_list + ['class_%d_preds' % n_class]].rename(\n",
    "                columns={'class_%d_preds' % n_class: 'preds'})\n",
    "            pdp_interact_out.append(\n",
    "                PDPInteract(which_class=n_class,\n",
    "                            pdp_isolate_outs=[pdp_isolate_outs[i][n_class] for i in range(nr_feats)],\n",
    "                            pdp=_pdp, **pdp_interact_params))\n",
    "    else:\n",
    "        pdp_interact_out = PDPInteract(\n",
    "            which_class=None, pdp_isolate_outs=pdp_isolate_outs, pdp=pdp, **pdp_interact_params)\n",
    "\n",
    "    return pdp_interact_out\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(arr): return arr - np.mean(arr)\n",
    "import itertools\n",
    "def compute_f_vals(mdl, X, features, selectedfeatures, num_grid_points=10, use_data_grid=False):\n",
    "    f_vals = {}\n",
    "    data_grid = None\n",
    "    if use_data_grid:\n",
    "        data_grid = X[selectedfeatures].values\n",
    "    # Calculate partial dependencies for full feature set\n",
    "    p_full = pdp_multi_interact(mdl, X, features, selectedfeatures, \n",
    "                                num_grid_points=[num_grid_points] * len(selectedfeatures),\n",
    "                                cust_grid_combos=data_grid,\n",
    "                                use_custom_grid_combos=use_data_grid)\n",
    "    f_vals[tuple(selectedfeatures)] = center(p_full.pdp.preds.values)\n",
    "    grid = p_full.pdp.drop('preds', axis=1)\n",
    "    # Calculate partial dependencies for [1..SFL-1]\n",
    "    for n in range(1, len(selectedfeatures)):\n",
    "        for subsetfeatures in itertools.combinations(selectedfeatures, n):\n",
    "            if use_data_grid:\n",
    "                data_grid = X[list(subsetfeatures)].values\n",
    "            p_partial = pdp_multi_interact(mdl, X, features, subsetfeatures, \n",
    "                                        num_grid_points=[num_grid_points] * len(selectedfeatures),\n",
    "                                        cust_grid_combos=data_grid,\n",
    "                                        use_custom_grid_combos=use_data_grid)\n",
    "            p_joined = pd.merge(grid, p_partial.pdp, how='left')\n",
    "            f_vals[tuple(subsetfeatures)] = center(p_joined.preds.values)\n",
    "    return f_vals\n",
    "def compute_h_val(f_vals, selectedfeatures):\n",
    "    denom_els = f_vals[tuple(selectedfeatures)].copy()\n",
    "    numer_els = f_vals[tuple(selectedfeatures)].copy()\n",
    "    sign = -1.0\n",
    "    for n in range(len(selectedfeatures)-1, 0, -1):\n",
    "        for subfeatures in itertools.combinations(selectedfeatures, n):\n",
    "            print(tuple(subfeatures))\n",
    "            numer_els += sign * f_vals[tuple(subfeatures)]\n",
    "        sign *= -1.0\n",
    "    numer = np.sum(numer_els**2)\n",
    "    denom = np.sum(denom_els**2)\n",
    "    return math.sqrt(numer/denom) if numer < denom else np.nan\n",
    "def compute_h_val_any(f_vals, allfeatures, selectedfeature):\n",
    "    otherfeatures = list(allfeatures)\n",
    "    otherfeatures.remove(selectedfeature)\n",
    "    denom_els = f_vals[tuple(allfeatures)].copy()\n",
    "    numer_els = denom_els.copy()\n",
    "    numer_els -= f_vals[(selectedfeature,)]\n",
    "    numer_els -= f_vals[tuple(otherfeatures)]\n",
    "    numer = np.sum(numer_els**2)\n",
    "    denom = np.sum(denom_els**2)\n",
    "    return math.sqrt(numer/denom) if numer < denom else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_interactions(model,X_train,feature_all,feature_select_list):  \n",
    "    result_dict={}\n",
    "    for i in range(len(feature_select_list)):\n",
    "        for j in range(len(feature_select_list)):\n",
    "            if i<j :\n",
    "                print(i,j)\n",
    "                current_features=[feature_select_list[i],feature_select_list[j]]\n",
    "                f_vals=compute_f_vals(model, X_train, feature_all,current_features) \n",
    "                result_dict[tuple(current_features)]=compute_h_val(f_vals,current_features)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_best(model,param,algorithm_name):\n",
    "    print('start')\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5,n_jobs=-1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    print('Best Classifier:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    best_model=grid.best_estimator_\n",
    "    return best_model\n",
    "def prediction(model,input_data):\n",
    "    return model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########LightGBM gridsearch CV for best hyperparameter##########\n",
    "model_LightGBMRegressor=lightgbm.LGBMRegressor(random_state=1,verbose=-1)\n",
    "param_light = {\n",
    " 'boosting_type':['gbdt'],\n",
    " 'learning_rate':[0.0075],\n",
    " 'n_estimators':[100],\n",
    "    'max_depth':[9],\n",
    " 'subsample':[0.5],\n",
    " 'reg_alpha':[0],\n",
    " 'reg_lambda':[1e-05]\n",
    "}\n",
    "LGBM=gridsearch_best(model_LightGBMRegressor,param_light,'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_DICT=compute_interactions(LGBM,X_train,raw_param.columns,\n",
    "                     [\n",
    "'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH'\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LGBM_CDREG.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in LGBM_DICT.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########XGBoost gridsearch CV for best hyperparameter##########\n",
    "model_XGBRegressor=xgboost.XGBRegressor(objective='reg:squarederror',random_state=1,verbose=0)\n",
    "param_xg = {\n",
    " 'booster':['gbtree'],\n",
    " 'learning_rate':[0.0025],\n",
    " 'n_estimators':[400],\n",
    " 'max_depth':[11],\n",
    " 'subsample':[0.7],\n",
    " 'reg_alpha':[1e-05],\n",
    " 'reg_lambda':[0.001]\n",
    "}\n",
    "XG=gridsearch_best(model_XGBRegressor,param_xg,'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_DICT=compute_interactions(XG,X_train,raw_param.columns,\n",
    "                     [\n",
    "'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH'\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('XG_CDREG.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in XG_DICT.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########CatBoost gridsearch CV for best hyperparameter##########\n",
    "model_CatRegressor=catboost.CatBoostRegressor(random_state=1,verbose=0)\n",
    "param_cat = {\n",
    " 'learning_rate':[0.25],\n",
    " 'n_estimators':[50],\n",
    " 'max_depth':[5],\n",
    " 'subsample':[0.8],\n",
    "    'reg_lambda':[0.01]\n",
    "}\n",
    "CAT=gridsearch_best(model_CatRegressor,param_cat,'CatBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_DICT=compute_interactions(CAT,X_train,raw_param.columns,\n",
    "                     [\n",
    "'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH'\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CAT_CDREG.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in CAT_DICT.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########GradientBoost gridsearch CV for best hyperparameter##########\n",
    "model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    " 'learning_rate':[0.025],\n",
    "                'criterion':['mse'],\n",
    "                 'max_features':['auto'],\n",
    "                 'loss':['huber'],\n",
    "    'max_depth':[7]\n",
    "}\n",
    "GB=gridsearch_best(model_GradientBoostingRegressor,param_GB,'GradientBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_DICT=compute_interactions(GB,X_train,raw_param.columns,\n",
    "                     [\n",
    "'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH'\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GB_CDREG.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in GB_DICT.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestRegressor = ensemble.RandomForestRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "    'n_estimators':[200],\n",
    "     'max_depth':[None],\n",
    "            'criterion':['mse'],\n",
    "            'max_features':['sqrt']\n",
    "}\n",
    "RF=gridsearch_best(model_RandomForestRegressor,param_RF,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_DICT=compute_interactions(RF,X_train,raw_param.columns,\n",
    "                     [\n",
    "'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH'\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RF_CDREG.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in RF_DICT.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Extra Tree gridsearch CV for best hyperparameter##########\n",
    "model_ExtraTreeRegressor = ExtraTreeRegressor(random_state=1)\n",
    "param_ET = {\n",
    "        'max_depth':[11],\n",
    "               'max_features':['auto'],\n",
    "               'criterion' : [ \"mae\"],\n",
    "               'splitter' : [ 'random']\n",
    "}\n",
    "ET=gridsearch_best(model_ExtraTreeRegressor,param_ET,'Extra Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET_DICT=compute_interactions(ET,X_train,raw_param.columns,\n",
    "                     [\n",
    "'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH'\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ET_CDREG.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in ET_DICT.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Decision Tree gridsearch CV for best hyperparameter##########\n",
    "model_DecisionTreeRegressor = tree.DecisionTreeRegressor(random_state=1)\n",
    "param_DT = {\n",
    "        'max_depth':[11],\n",
    "               'max_features':['auto'],\n",
    "               'criterion' : [ \"mae\"],\n",
    "               'splitter' : [ 'random']\n",
    "}\n",
    "DT=gridsearch_best(model_DecisionTreeRegressor,param_DT,'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_DICT=compute_interactions(DT,X_train,raw_param.columns,\n",
    "                     [\n",
    "'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH'\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DT_CDREG.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in DT_DICT.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########AdaBoost gridsearch CV for best hyperparameter##########\n",
    "model_AdaBoostRegressor = ensemble.AdaBoostRegressor(random_state=1)\n",
    "param_Ada = {\n",
    "     'n_estimators':[50],\n",
    "     'learning_rate':[0.01],\n",
    "            'loss':[ 'linear']\n",
    "}\n",
    "ADA=gridsearch_best(model_AdaBoostRegressor,param_Ada,'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA_DICT=compute_interactions(ADA,X_train,raw_param.columns,\n",
    "                     [\n",
    "'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Biomass or other Organic Derived',#5\n",
    "                      'Main Transition Metal Content (wt. %)',#6\n",
    "                      'Nitrogen Cotent (wt. %)',#7\n",
    "                      'Metal-N Coordination Number (XAS)',#8    \n",
    "                      'Pyridinic N Ratio',#9\n",
    "                      'Pyrrolic N Ratio',#10\n",
    "                      'Raman ID/IG Ratio',#11\n",
    "                      'BET Surface Area (m2/g)',#12\n",
    "                      'Pyrolysis Temperature (°C)',#13\n",
    "                      'Rising Rate (°C min-1)',#14\n",
    "                      'Flow Cell/H-type Cell',#15\n",
    "                      'Electrolyte Concentration (M)',#16\n",
    "                      'Catalyst Loading (mg cm-2)',#17\n",
    "                      'Electrolyte pH'\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ADA_CDREG.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in ADA_DICT.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
