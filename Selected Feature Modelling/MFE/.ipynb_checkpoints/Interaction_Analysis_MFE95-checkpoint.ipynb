{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn import linear_model\n",
    "import lightgbm\n",
    "import catboost\n",
    "import xgboost\n",
    "import shap\n",
    "from catboost import *\n",
    "%matplotlib\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database_filled.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[\n",
    "                      'Ionization Potential',#0\n",
    "                      'Electronegativity',#1\n",
    "                      'Number of d electrons',#2\n",
    "                      'ZIF or MOF Derived',#3\n",
    "                      'Carbon Nanofiber/Nanotubes',#4\n",
    "                      'Carbon Black Derived',#5\n",
    "                      'Biomass or other Organic Derived',#6 \n",
    "                      'Main Transition Metal Content (wt. %)',#7\n",
    "                      'Nitrogen Cotent (wt. %)',#8\n",
    "                      'Metal-N Coordination Number (XAS)',#9    \n",
    "                      'Pyridinic N Ratio',#10\n",
    "                      'Pyrrolic N Ratio',#11\n",
    "                      'Raman ID/IG Ratio',#12\n",
    "                      'BET Surface Area (m2/g)',#13\n",
    "                      'Pyrolysis Temperature (°C)',#14\n",
    "                      'Pyrolysis Time (h)',#15\n",
    "                      'Rising Rate (°C min-1)',#16\n",
    "                      'Electrolyte Concentration (M)',#17\n",
    "                      'Catalyst Loading (mg cm-2)',#18\n",
    "                      'Electrolyte pH',#19\n",
    "                      'FE95',#20\n",
    "                        ]]\n",
    "###########train test splitting##########\n",
    "raw_param=raw_data.iloc[:,0:20]\n",
    "raw_power=raw_data.iloc[:,20]\n",
    "print('ready')\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_curve(y_label, y_pre,algorithm_name):\n",
    "    y_label = y_label + 1\n",
    "    y_pre = y_pre + 1\n",
    "    fpr, tpr, thersholds = roc_curve(y_label, y_pre, pos_label=2)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    x_line=np.arange(0,1.01,0.01)\n",
    "    y_line=np.arange(0,1.01,0.01)\n",
    "    print('auc',roc_auc)\n",
    "    fig=plt.figure()\n",
    "    plt.plot(fpr, tpr, 'k--', label='ROC (AUC/area = {0:.2f})'.format(roc_auc), lw=2)\n",
    "    plt.plot(x_line,y_line,c='red')\n",
    "    plt.xlim([-0.05, 1.05])  # 设置x、y轴的上下限，以免和边缘重合，更好的观察图像的整体\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')  # 可以使用中文，但需要导入一些库即字体\n",
    "    plt.title('ROC Curve of %s' %algorithm_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig.savefig('FE90 ROC Curve of %s.png' %algorithm_name)\n",
    "def gridsearch(model,param,algorithm_name):\n",
    "    print('start')\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5,n_jobs=-1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    print('Best Classifier:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    best_model=grid.best_estimator_\n",
    "    prediction_train=best_model.predict(X_train)\n",
    "    prediction_test=best_model.predict(X_test)\n",
    "    final_result=classification_report(y_test,prediction_test,output_dict=True)\n",
    "    ##############################################################\n",
    "    y_score=best_model.predict_proba(X_test)\n",
    "    y_score=y_score[:,1]\n",
    "    auc_curve(y_test,y_score,algorithm_name)\n",
    "    ##############################################################\n",
    "    print(classification_report(y_train,prediction_train))\n",
    "    print(classification_report(y_test,prediction_test))\n",
    "    print(final_result['accuracy'])\n",
    "    ###########generating a figure##########\n",
    "    print(algorithm_name)\n",
    "    print(best_model.feature_importances_)\n",
    "    return best_model\n",
    "def shap_plot_interaction(best_model,algorithm_name,interacted_features):\n",
    "    print(algorithm_name)\n",
    "    SHAP_INPUT=raw_param\n",
    "    SHAP_OUTPUT=raw_power\n",
    "    print('train finished')\n",
    "    X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "    y_SHAP=SHAP_OUTPUT.values.astype(np.float32)\n",
    "\n",
    "    if algorithm_name=='CatBoost':\n",
    "        shap_values = best_model.get_feature_importance(Pool(X_SHAP,y_SHAP), type=\"ShapValues\")\n",
    "        shap_values=shap_values[:,:-1]\n",
    "#         print(shap_values)\n",
    "        interaction_values = best_model.get_feature_importance(Pool(SHAP_INPUT),type=EFstrType.ShapInteractionValues)\n",
    "        interaction_values=interaction_values[:,:-1,:-1]\n",
    "        shap.dependence_plot(interacted_features[0], shap_values, SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values, SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "    elif algorithm_name=='Random Forest' or algorithm_name=='Extra Tree'or algorithm_name=='Decision Tree'or algorithm_name=='AdaBoost':\n",
    "        explainer = shap.TreeExplainer(best_model,SHAP_INPUT)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)        \n",
    "        interaction_values = shap.TreeExplainer(best_model).shap_interaction_values(SHAP_INPUT) \n",
    "#         print(shap_values)\n",
    "        shap.dependence_plot(interacted_features[0], shap_values[1], SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values[1], SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(best_model,SHAP_INPUT)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)\n",
    "        interaction_values = shap.TreeExplainer(best_model).shap_interaction_values(SHAP_INPUT)\n",
    "#         print(shap_values)\n",
    "        shap.dependence_plot(interacted_features[0], shap_values, SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values, SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "from pdpbox import pdp\n",
    "def plot_pdp_interact_ANN(model, df, f_list, cluster_flag=False, nb_clusters=None, lines_flag=False):\n",
    "    \n",
    "    # Create the data that we will plot\n",
    "    inter1 = pdp.pdp_interact(model, df, model_features=df.columns.tolist(), features=f_list,num_grid_points=[20,20])\n",
    "    # plot it\n",
    "    settings = {\n",
    "            'contour_color':  'white',\n",
    "            'font_family': 'Arial',\n",
    "            # matplotlib color map for interact plot\n",
    "            'cmap': 'viridis',\n",
    "            # fill alpha for interact plot\n",
    "            'inter_fill_alpha': 0.8,\n",
    "            # fontsize for interact plot text\n",
    "            'inter_fontsize': 7,\n",
    "        }\n",
    "    pdp.pdp_interact_plot(\n",
    "    pdp_interact_out=inter1, feature_names=f_list, plot_type='contour',figsize=(10,10),x_quantile=True, plot_pdp=True,plot_params=settings\n",
    ")\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.utils import validation\n",
    "def pdp_plot_2d(best_model,f_list):\n",
    "    print('start')\n",
    "    validation.check_is_fitted(estimator=best_model)\n",
    "    my_plots =plot_partial_dependence(best_model, features=[f_list], X=raw_param, percentiles=(0, 1),grid_resolution=100)\n",
    "def pdp_plot_2d_XG_CAT(best_model,f_index):\n",
    "    print('start')\n",
    "    best_model.dummy_ = \"dummy\"\n",
    "    validation.check_is_fitted(estimator=best_model)\n",
    "    my_plots =plot_partial_dependence(best_model, features=[f_list], X=raw_param, percentiles=(0, 1),grid_resolution=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1222\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_param, raw_power, test_size=.1,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########LightGBM gridsearch CV for best hyperparameter##########\n",
    "model_LightGBMClassifier=lightgbm.LGBMClassifier(random_state=1,verbose=-1)\n",
    "param_light = {\n",
    "'boosting_type':['gbdt'],\n",
    " 'learning_rate':[0.07],\n",
    "  'n_estimators':[100],\n",
    " 'subsample':[0.35],\n",
    " 'max_depth':[5],\n",
    " 'reg_alpha':[0.01],\n",
    " 'reg_lambda':[0.01]\n",
    "}\n",
    "LGBM=gridsearch(model_LightGBMClassifier,param_light,'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########XGBoost gridsearch CV for best hyperparameter##########\n",
    "model_XGBClassifier=xgboost.XGBClassifier(objective ='reg:squarederror',random_state=1,verbose=0)\n",
    "param_xg = {\n",
    "'booster':['gbtree'],\n",
    "'learning_rate':[0.028],\n",
    "'n_estimators':[200],\n",
    "'max_depth':[5],\n",
    "'subsample':[0.7],\n",
    "'reg_alpha':[0.01],\n",
    "'reg_lambda':[0.001]\n",
    "}\n",
    "XG=gridsearch(model_XGBClassifier,param_xg,'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########GradientBoost gridsearch CV for best hyperparameter##########\n",
    "model_GradientBoostingClassifier = ensemble.GradientBoostingClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    "'learning_rate':[0.04],\n",
    "'n_estimators':[50],\n",
    "'criterion':['friedman_mse'],\n",
    "'max_features':['sqrt'],\n",
    "'loss':['exponential'],\n",
    "'max_depth':[7]\n",
    "}\n",
    "GB=gridsearch(model_GradientBoostingClassifier,param_GB,'GradientBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestClassifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "'n_estimators':[400],\n",
    "'max_depth':[7],\n",
    "'criterion':['gini'],\n",
    "'max_features':['auto']\n",
    "}\n",
    "RF=gridsearch(model_RandomForestClassifier,param_RF,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(LGBM,algorithm_name=\"LightGBM\",interacted_features=[\"Nitrogen Cotent (wt. %)\",\"Main Transition Metal Content (wt. %)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d(LGBM,[\"Number of d electrons\",\"Ionization Potential\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(XG,algorithm_name=\"XGBoost\",interacted_features=[\"Nitrogen Cotent (wt. %)\",\"Main Transition Metal Content (wt. %)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d(XG,[\"Nitrogen Cotent (wt. %)\",\"Main Transition Metal Content (wt. %)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(GB,algorithm_name=\"Gradient Boost\",interacted_features=[\"Nitrogen Cotent (wt. %)\",\"Main Transition Metal Content (wt. %)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d(GB,[\"Nitrogen Cotent (wt. %)\",\"Main Transition Metal Content (wt. %)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "shap_plot_interaction(RF,algorithm_name=\"Random Forest\",interacted_features=[\"Nitrogen Cotent (wt. %)\",\"Main Transition Metal Content (wt. %)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d(RF,[\"Nitrogen Cotent (wt. %)\",\"Main Transition Metal Content (wt. %)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
